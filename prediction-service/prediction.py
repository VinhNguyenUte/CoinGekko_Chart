import os
import time
import logging
import schedule
import psycopg2
import joblib
import pandas as pd
import numpy as np
import threading
import uvicorn

from fastapi import FastAPI, BackgroundTasks
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from urllib.parse import urlparse

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
TARGET_COINS = ["bitcoin", "ethereum", "solana", "dogecoin", "tether"]
app = FastAPI(title="Prediction Service API", description="Full AI Prediction & Classification")

# C·∫•u h√¨nh th∆∞ m·ª•c l∆∞u model
MODEL_DIR = "/models"
if not os.path.exists(MODEL_DIR):
    os.makedirs(MODEL_DIR)

# K·∫øt n·ªëi DB
def get_db_connection():
    db_url = os.getenv("DATABASE_URL")
    if not db_url:
        # Fallback cho test local n·∫øu kh√¥ng c√≥ env
        # db_url = "postgres://user:pass@localhost:5432/crypto_db" 
        logging.error("DATABASE_URL not set.")
        return None
    try:
        parsed = urlparse(db_url)
        conn = psycopg2.connect(
            dbname=parsed.path.lstrip("/"), user=parsed.username,
            password=parsed.password, host=parsed.hostname, port=parsed.port
        )
        return conn
    except Exception as e:
        logging.error(f"DB Connect Error: {e}")
        return None

# T·ª± ƒë·ªông t·∫°o b·∫£ng v√† c·∫≠p nh·∫≠t schema n·∫øu c·∫ßn
def ensure_schema_exists():
    conn = get_db_connection()
    if not conn: return
    try:
        cur = conn.cursor()
        
        # 1. T·∫°o b·∫£ng k·∫øt qu·∫£ d·ª± ƒëo√°n (ƒê√£ th√™m current_price)
        cur.execute("""
            CREATE TABLE IF NOT EXISTS price_predictions (
                id SERIAL PRIMARY KEY,
                coin_id TEXT,
                current_price DOUBLE PRECISION,  -- <--- TH√äM C·ªòT N√ÄY
                predicted_price DOUBLE PRECISION,
                signal TEXT,
                confidence DOUBLE PRECISION,
                factors TEXT,
                created_at TIMESTAMP,
                prediction_target_date DATE
            )
        """)

        # 2. Migration c·ªôt (ƒê·ªÉ update b·∫£ng c≈© n·∫øu ch∆∞a c√≥ c·ªôt n√†y)
        cols = [
            ("current_price", "DOUBLE PRECISION"), # <--- TH√äM V√ÄO MIGRATION
            ("signal", "TEXT"),
            ("confidence", "DOUBLE PRECISION"),
            ("factors", "TEXT"),
            ("created_at", "TIMESTAMP"),
            ("prediction_target_date", "DATE")
        ]
        for col_name, col_type in cols:
            cur.execute(f"ALTER TABLE price_predictions ADD COLUMN IF NOT EXISTS {col_name} {col_type};")

        # 3. Constraint Unique
        try:
            cur.execute("ALTER TABLE price_predictions DROP CONSTRAINT IF EXISTS unique_prediction;")
            cur.execute("ALTER TABLE price_predictions DROP CONSTRAINT IF EXISTS unique_prediction_entry;")
            cur.execute("""
                ALTER TABLE price_predictions 
                ADD CONSTRAINT unique_prediction_entry UNIQUE (coin_id, created_at);
            """)
        except Exception as e:
            logging.warning(f"Constraint adjustment warning: {e}")

        conn.commit()
        cur.close()
    except Exception as e:
        logging.error(f"Schema Update Error: {e}")
    finally:
        conn.close()

# T√≠nh c√°c features t·ª´ d·ªØ li·ªáu l·ªãch s·ª≠ 
def calculate_features(df):
    df = df.sort_values(by='timestamp', ascending=True).reset_index(drop=True)

    try:
        # Price Features
        df['ma7'] = df['current_price'].rolling(window=7).mean()
        df['ma20'] = df['current_price'].rolling(window=20).mean()
        df['volatility'] = df['current_price'].rolling(window=7).std()
        
        # RSI
        delta = df['current_price'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        
        # Lags l√† c√°c gi√° tr·ªã tr·ªÖ tr√™n 1 ng√†y, 3 ng√†y, 7 ng√†y
        df['lag_1'] = df['current_price'].shift(1)
        df['lag_3'] = df['current_price'].shift(3)
        df['lag_7'] = df['current_price'].shift(7)

        # Volume & Market Cap Features
        df['vol_change'] = df['total_volume'].pct_change()
        df['vol_ma7'] = df['total_volume'].rolling(window=7).mean()
        df['cap_change'] = df['market_cap'].pct_change()

        # Targets
        df['next_day_price'] = df['current_price'].shift(-1)
        df['target_trend'] = (df['next_day_price'] > df['current_price']).astype(int)
        
        df.dropna(subset=['ma20', 'rsi', 'lag_7', 'vol_ma7'], inplace=True)

        return df
    except Exception as e:
        logging.error(f"Feature Calculation Error: {e}")
        return df

# --- L·∫§Y D·ªÆ LI·ªÜU ---
def get_historical_data(coin_id):
    conn = get_db_connection()
    if not conn: return None
    try:
        query = """
            SELECT DISTINCT ON ("timestamp"::date)
                "timestamp", 
                current_price, 
                market_cap, 
                total_volume 
            FROM price_history 
            WHERE coin_id = %s 
              AND "timestamp" >= NOW() - INTERVAL '365 days'
            ORDER BY "timestamp"::date ASC, "timestamp" DESC
        """
        df = pd.read_sql_query(query, conn, params=(coin_id,))
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'])
        return df
    except Exception as e:
        logging.error(f"Fetch Error {coin_id}: {e}")
        return None
    finally:
        conn.close()

# --- L∆ØU K·∫æT QU·∫¢ ---
def save_to_db(coin_id, current_price, predicted_price, signal, confidence, factors):
    conn = get_db_connection()
    if not conn: return
    try:
        cur = conn.cursor()
        now = datetime.now()
        target_date = now.date() + timedelta(days=1)

        # ƒê√£ c·∫≠p nh·∫≠t c√¢u l·ªánh INSERT ƒë·ªÉ bao g·ªìm current_price
        cur.execute("""
            INSERT INTO price_predictions 
            (coin_id, current_price, predicted_price, signal, confidence, factors, created_at, prediction_target_date)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (coin_id, created_at) DO NOTHING;
        """, (coin_id, float(current_price), float(predicted_price), signal, float(confidence), factors, now, target_date))
        
        conn.commit()
        cur.close()
        logging.info(f"‚úÖ Predicted {coin_id}: Now ${current_price:.2f} -> Next ${predicted_price:.2f} | {signal}")
    except Exception as e:
        logging.error(f"Save Error: {e}")
    finally:
        conn.close()

# define feature list used globally
FEATURES = [
    'lag_1', 'lag_3', 'lag_7', 
    'ma7', 'ma20', 'volatility', 'rsi',
    'vol_change', 'vol_ma7', 'cap_change'
]

# ==============================================================================
# 1. TRAINING TASK
# ==============================================================================
def run_training_task():
    logging.info(">>> STARTING MODEL TRAINING TASK...")
    ensure_schema_exists()
    
    for coin in TARGET_COINS:
        df = get_historical_data(coin)
        if df is None or len(df) < 30:
            logging.warning(f"Skipping TRAIN {coin}: Not enough data.")
            continue

        df = calculate_features(df)
        
        # B·ªè d√≤ng cu·ªëi c√πng
        df_train = df.dropna(subset=['next_day_price']).copy()
        if len(df_train) < 20: continue

        X_train = df_train[FEATURES]
        y_price = df_train['next_day_price']
        y_trend = df_train['target_trend']

        try:
            # 1. Train Price Model (Regressor)
            reg_path = os.path.join(MODEL_DIR, f"{coin}_price.pkl")
            reg_model = RandomForestRegressor(n_estimators=100, random_state=42)
            reg_model.fit(X_train, y_price)
            joblib.dump(reg_model, reg_path)
            logging.info(f"üíæ Saved Price Model: {coin}")

            # 2. Train Trend Model (Classifier)
            clf_path = os.path.join(MODEL_DIR, f"{coin}_trend.pkl")
            clf_model = RandomForestClassifier(n_estimators=100, random_state=42)
            clf_model.fit(X_train, y_trend)
            joblib.dump(clf_model, clf_path)
            logging.info(f"ƒê√£ l∆∞u model cho {coin}")

        except Exception as e:
            logging.error(f"Train th·∫•t b·∫°i {coin}: {e}")

    logging.info("TRAINING Th√†nh c√¥ng.")

# ==============================================================================
# 2. PREDICTION TASK
# ==============================================================================
def run_prediction_task():
    logging.info(">>> STARTING PREDICTION TASK...")
    ensure_schema_exists()
    for coin in TARGET_COINS:
        reg_path = os.path.join(MODEL_DIR, f"{coin}_price.pkl")
        clf_path = os.path.join(MODEL_DIR, f"{coin}_trend.pkl")
        
        if not os.path.exists(reg_path) or not os.path.exists(clf_path):
            logging.warning(f"Kh√¥ng t√¨m th·∫•y model cho {coin}. Vui l√≤ng ch·∫°y /train tr∆∞·ªõc.")
            continue

        df = get_historical_data(coin)
        if df is None or len(df) < 30: continue
        df = calculate_features(df)
        
        last_row = df.iloc[[-1]]
        # KI·ªÇM TRA D·ªÆ LI·ªÜU ƒê·∫¶Y ƒê·ª¶
        if last_row[FEATURES].isnull().values.any():
            logging.warning(f"Skipping {coin}: D·ªØ li·ªáu ng√†y m·ªõi nh·∫•t ch∆∞a ƒë·ªß ƒë·ªÉ t√≠nh ch·ªâ b√°o.")
            continue
        X_pred = last_row[FEATURES]
        
        # L·∫§Y GI√Å HI·ªÜN T·∫†I T·ª™ D·ªÆ LI·ªÜU
        current_price = float(last_row['current_price'].values[0])

        try:
            reg_model = joblib.load(reg_path)
            predicted_price = reg_model.predict(X_pred)[0]

            clf_model = joblib.load(clf_path)
            pred_class = clf_model.predict(X_pred)[0]
            pred_proba = clf_model.predict_proba(X_pred)[0]
            confidence = max(pred_proba) * 100
            
            # ... (ƒêo·∫°n l·∫•y current_price v√† predicted_price)

            # 1. T√≠nh % l·ª£i nhu·∫≠n k·ª≥ v·ªçng
            price_change_pct = ((predicted_price - current_price) / current_price) * 100

            # 2. Ng∆∞·ª°ng t·ªëi thi·ªÉu ƒë·ªÉ v√†o l·ªánh (V√≠ d·ª•: ph·∫£i l√£i h∆°n ph√≠ s√†n 0.1% + tr∆∞·ª£t gi√°)
            MIN_PROFIT_THRESHOLD = 0.5  # 0.5%

            # 3. Logic ra quy·∫øt ƒë·ªãnh
            if pred_class == 1: # Classifier b·∫£o TƒÇNG
                if price_change_pct >= MIN_PROFIT_THRESHOLD:
                    signal = "STRONG BUY"
                    trend_text = f"UP (+{price_change_pct:.2f}%)"
                elif price_change_pct > 0:
                    signal = "WEAK BUY" # TƒÉng nh∆∞ng kh√¥ng ƒë·ªß b√π ph√≠
                    trend_text = f"UP (Only +{price_change_pct:.2f}%)"
                else:
                    signal = "CONFLICT" # Classifier b·∫£o TƒÉng m√† Gi√° d·ª± ƒëo√°n l·∫°i Gi·∫£m
                    trend_text = f"Trend: {'UP' if pred_class == 1 else 'DOWN'} but Price Change: {price_change_pct:.2f}%"

            elif pred_class == 0: # Classifier b·∫£o GI·∫¢M
                if price_change_pct <= -MIN_PROFIT_THRESHOLD:
                    signal = "STRONG SELL"
                    trend_text = f"DOWN ({price_change_pct:.2f}%)"
                else:
                    signal = "NEUTRAL" # Gi·∫£m nh∆∞ng kh√¥ng ƒë·ªß ƒë·ªÉ v√†o l·ªánh
                    trend_text = "Sideway"

            # ... (L∆∞u signal v√† trend_text v√†o DB)
            
            try:
                importances = clf_model.feature_importances_
                top_idx = np.argmax(importances)
                top_feature = FEATURES[top_idx]
            except:
                top_feature = "Unknown"

            factors = f"Trend: {trend_text} | Key: {top_feature}"
            
            # TRUY·ªÄN current_price V√ÄO H√ÄM SAVE
            save_to_db(coin, current_price, predicted_price, signal, confidence, factors)
            
        except Exception as e:
            logging.error(f"Prediction Error {coin}: {e}")
    
    logging.info("PREDICTION TH√ÄNH C√îNG.")

# --- API ---
@app.post("/predict")
async def trigger_prediction(background_tasks: BackgroundTasks):
    """Ch·ªâ k√≠ch ho·∫°t d·ª± ƒëo√°n"""
    background_tasks.add_task(run_prediction_task)
    return {"status": "Prediction triggered"}

@app.post("/train")
async def trigger_training(background_tasks: BackgroundTasks):
    """K√≠ch ho·∫°t hu·∫•n luy·ªán"""
    background_tasks.add_task(run_training_task)
    return {"status": "Training ƒëa ƒë∆∞·ª£c k√≠ch ho·∫°t"}

# --- SCHEDULER ---
def run_scheduler():
    while True:
        schedule.run_pending()
        time.sleep(1)

if __name__ == "__main__":
    time.sleep(8) 
    try:
        test_path = os.path.join(MODEL_DIR, f"{TARGET_COINS[0]}_price.pkl")
        if not os.path.exists(test_path):
            logging.info("First run detected (no models). Starting initial training...")
            t_train = threading.Thread(target=run_training_task)
            t_train.start()
            t_train.join()
        else:
            logging.info("First run detected (models exist). Starting server...")
            # Ch·∫°y trong thread ri√™ng ƒë·ªÉ kh√¥ng block vi·ªác start uvicorn
            run_prediction_task()
    except Exception as e:
        logging.error(f"Startup error: {e}")
    
    schedule.every(5).minutes.do(run_prediction_task)
    schedule.every(24).hours.do(run_training_task)
    
    t = threading.Thread(target=run_scheduler, daemon=True)
    t.start()
    uvicorn.run(app, host="0.0.0.0", port=5003)